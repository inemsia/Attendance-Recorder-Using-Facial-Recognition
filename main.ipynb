{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Creating A Facial Detection and Recognition Model\n",
    "# Idris Nemsia\n",
    "More documentation will be included in the future version\n",
    "## References\n",
    "To build my model, I have consulted some references to guide my coding process.\n",
    "[1] : J. Loy. Implementing a Facial Recognition System with Neural Networks. Neural Network Projects with Python. Packt Publishing, February 2019.\n",
    "[2] : Koch et al. Siamese Neural Networks for One-shot Image Recognition. ICML deep learning workshop, vol. 2. 2015.\n",
    "[3] : Build a Facial Recognition App // Deep Learning Project // Paper2Code Series. https://www.youtube.com/playlist?list=PLgNJO2hghbmhHuhURAGbe6KWpiYZt0AMH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initial Preparations Section\n",
    "These section includes the installation of some of our needed modules. It also imports the modules we will be using."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "# Installing Tensorflow and opencv\n",
    "# !pip install --user tensorflow==2.10.1 opencv-python\n",
    "#!pip install keras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# Import Sequential and Functional Tenserflow API, as well as layers\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Input\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading our data\n",
    "We will be using ORL AT&T Dataset of Faces. (*More information will be included in future documentation)\n",
    "In this section, we initialize our preset input and output arrays (X_train, Y_train, X_test, Y_test).\n",
    "We import the folder containing the dataset of images. The folder contains 40 folders, each containing pictures of one person. We split the folders into 35 to 5 folders for training and testing data. We convert these images into numpy arrays containing numerical values. We add the numpy arrays of images to our input and output arrays accordingly."
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 1,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3160792744.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[1], line 2\u001B[1;36m\u001B[0m\n\u001B[1;33m    We will be using...\u001B[0m\n\u001B[1;37m       ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 92, 1)\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty X,Y training and test arrays\n",
    "X_train, Y_train = [], []\n",
    "X_test, Y_test = [], []\n",
    "# Define the dataset path\n",
    "dataset_path = \"dataset\"\n",
    "# List of DirEntry Objects. These objects contain path attributes.\n",
    "dataset = os.listdir(dataset_path)\n",
    "dataset = sorted(dataset)\n",
    "# Our training data is 1-35, test data is 35-40\n",
    "# Loop through the folders inside the dataset\n",
    "for folder_index in range(1,41):\n",
    "    person_name = dataset[folder_index]\n",
    "    person_folder_path = dataset_path + \"/\" + person_name\n",
    "    person_folder = os.listdir(person_folder_path)\n",
    "    # Loop through images in each person's folder\n",
    "    for img_name in person_folder:\n",
    "        img_path = person_folder_path + '/' + img_name\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img_array = np.array(img)\n",
    "        img_array = np.expand_dims(img, axis=2)\n",
    "        # Splitting dataset_path\n",
    "        if folder_index <= 35:\n",
    "            X, Y = X_train, Y_train\n",
    "        else:\n",
    "            X, Y = X_test, Y_test\n",
    "        X.append(img_array)\n",
    "        Y.append(person_name)\n",
    "\n",
    "img_shape = X_train[0].shape\n",
    "print(img_shape)\n",
    "img_width, img_height = img_shape[0], img_shape[1]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating our Model\n",
    "### Creating the feature generating model\n",
    "The layers of this section follow the layers explained in [2]. However, more modifications will be made to this code as Max Pooling layers are incomplete. This is causing the loss value to be NaN during the training of my model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "# The sequential model allows us to connect layers that each receive inputs and can send their outputs to the next layer\n",
    "feature_generation_network = Sequential()\n",
    "feature_generation_network.add(Conv2D(filters=64, kernel_size=(10,10), activation='relu',input_shape=img_shape))\n",
    "feature_generation_network.add(MaxPooling2D())\n",
    "feature_generation_network.add(Conv2D(filters=128, kernel_size=(7,7), activation='relu'))\n",
    "feature_generation_network.add(MaxPooling2D())\n",
    "feature_generation_network.add(Conv2D(filters=128, kernel_size=(4,4), activation='relu'))\n",
    "feature_generation_network.add(MaxPooling2D())\n",
    "feature_generation_network.add(Conv2D(filters=256, kernel_size=(4,4), activation='relu'))\n",
    "feature_generation_network.add(Flatten())\n",
    "feature_generation_network.add(Dense(units=4096, activation='sigmoid'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_49 (Conv2D)          (None, 103, 83, 64)       6464      \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 51, 41, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 45, 35, 128)       401536    \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPoolin  (None, 22, 17, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 19, 14, 128)       262272    \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 9, 7, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 6, 4, 256)         524544    \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 6144)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4096)              25169920  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,364,736\n",
      "Trainable params: 26,364,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_generation_network.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Defining the inputs and outputs\n",
    "The outputs here refer to the network used to generate features inside our siamese neural network for each input. The two outputs of the feature_generation_network from input1 and input2 will then be compared by calculating the Euclidean distance between them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "input1, input2 = Input(shape=img_shape), Input(shape=img_shape)\n",
    "# Share the single output layer for both inputs\n",
    "output1, output2 = feature_generation_network(input1), feature_generation_network(input2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining the output of the siamese_network: Distance between our two inital outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "distance = tf.norm(output1 - output2, axis=1, keepdims=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize Siamese Neural Network Model with inputs and outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "siamese_network = Model((input1, input2), distance)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get Summary of our model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_17 (InputLayer)          [(None, 112, 92, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " input_18 (InputLayer)          [(None, 112, 92, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " sequential_14 (Sequential)     (None, 4096)         26364736    ['input_17[0][0]',               \n",
      "                                                                  'input_18[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.subtract_7 (TFOpLambda  (None, 4096)        0           ['sequential_14[0][0]',          \n",
      " )                                                                'sequential_14[1][0]']          \n",
      "                                                                                                  \n",
      " tf.compat.v1.norm_7 (TFOpLambd  (None, 1)           0           ['tf.math.subtract_7[0][0]']     \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 26,364,736\n",
      "Trainable params: 26,364,736\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_network.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training our model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Loss Function: Contrastive Loss function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "# This follows the loss function explained in [1], [2], [3]\n",
    "def contrastive_loss(true_pair_label, distance):\n",
    "    true_pair_label = tf.cast(true_pair_label, tf.float32)\n",
    "    loss = true_pair_label * tf.square(distance) + (1 - true_pair_label) * tf.square(tf.maximum(1 - distance, 0))\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compile our model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "siamese_network.compile(loss=contrastive_loss, optimizer='adam')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating X_train, Y_train, X_test, Y_test using pairs of images and their outputs (0 or 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "import random\n",
    "# This function finds a positive pair of images within a set of images\n",
    "def positive_pair(X, number_of_people):\n",
    "    picture1_index = random.randint(0,9)\n",
    "    picture2_index = picture1_index\n",
    "    while picture2_index == picture1_index:\n",
    "        picture2_index = random.randint(0,9)\n",
    "    random_person_index = random.randint(0,number_of_people - 1)\n",
    "    picture1_index = random_person_index * 10 + picture1_index\n",
    "    picture2_index = random_person_index * 10 + picture2_index\n",
    "    return np.array((X[picture1_index], X[picture2_index]))\n",
    "\n",
    "# This function finds a negative pair of images within a set of images\n",
    "def negative_pair(X, number_of_people):\n",
    "    person1_index = random.randint(0,number_of_people - 1)\n",
    "    person2_index = person1_index\n",
    "    while person2_index == person1_index:\n",
    "        person2_index = random.randint(0,number_of_people - 1)\n",
    "    picture1_index = random.randint(0,9)\n",
    "    picture2_index = random.randint(0,9)\n",
    "    picture1_index = person1_index * 10 + picture1_index\n",
    "    picture2_index = person2_index * 10 + picture2_index\n",
    "    return np.array((X[picture1_index], X[picture2_index]))\n",
    "\n",
    "# This function creates a list of random input pairs (X) and a list of their labels (Y) from a set of images.\n",
    "# It alternates between adding a positive and negative pair of images to X with matching labels to Y.\n",
    "def create_X_pairs(X, number_of_people, size):\n",
    "    X_pairs, X_pairs_labels = [], []\n",
    "    for i in range(size):\n",
    "        if i % 2 == 0:\n",
    "            X_pairs.append(positive_pair(X, number_of_people))\n",
    "            X_pairs_labels.append(1)\n",
    "        else:\n",
    "            X_pairs.append(negative_pair(X,number_of_people))\n",
    "            X_pairs_labels.append(0)\n",
    "    return (X_pairs, X_pairs_labels)\n",
    "\n",
    "# Creating our training and data sets for pairs of images\n",
    "# These are the sets that the siamese network will take the input from.\n",
    "## Currently, I am still modifying the sizes of my sets of pairs and labels for training\n",
    "## and testing. I believe that this may be affecting the error of the loss function\n",
    "## during the training of the model.\n",
    "X_pairs_train, Y_pairs_train = create_X_pairs(X_train, 35, 100)\n",
    "X_pairs_test, Y_pairs_test = create_X_pairs(X_test, 5, 5)\n",
    "# Turning our training and testing sets into numpy arrays\n",
    "X_pairs_train = np.array(X_pairs_train)\n",
    "Y_pairs_train = np.array(Y_pairs_train)\n",
    "X_pairs_test = np.array(X_pairs_test)\n",
    "Y_pairs_test = np.array(Y_pairs_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exporting our model to be integrated into a web application"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "34/34 [==============================] - 13s 382ms/step - loss: nan\n",
      "Epoch 2/5\n",
      " 5/34 [===>..........................] - ETA: 11s - loss: nan"
     ]
    }
   ],
   "source": [
    "# Creating numpy arrays for the first and second element of each pair\n",
    "X1_train = np.array([pair[0] for pair in X_pairs_train])\n",
    "X2_train = np.array([pair[1] for pair in X_pairs_train])\n",
    "# Training the model\n",
    "## This currently runs. However, the loss output is incorrect, as it starts with numerical values but then\n",
    "## turns into NaN. This negatively affects the training of my siamese network. I am currently working\n",
    "## on fixing this error.\n",
    "## I will also be modifying the batch_size and epochs size to see if it affects my results\n",
    "siamese_network.fit(x=[X1_train, X2_train], y = Y_pairs_train, batch_size = 3, epochs=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Next Steps\n",
    "1) Fixing the current error in the training of my module. (Incorrect loss value output)\n",
    "2) Testing my module\n",
    "3) Exporting the module and creating the interface of the application in which I will be using it to record attendance with facial recognition."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
