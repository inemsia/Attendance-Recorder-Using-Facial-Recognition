{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Creating A Facial Detection and Recognition Model\n",
    "# Idris Nemsia\n",
    "In this program, I build and train a Siamese Neural Network for attendance recording. Below are the references I used while building this program.\n",
    "## References\n",
    "To build my model, I have consulted some references to guide my coding process.\n",
    "[1] : J. Loy. Implementing a Facial Recognition System with Neural Networks. Neural Network Projects with Python. Packt Publishing, February 2019.\n",
    "[2] : Build a Facial Recognition App // Deep Learning Project // Paper2Code Series. https://www.youtube.com/playlist?list=PLgNJO2hghbmhHuhURAGbe6KWpiYZt0AMH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initial Preparations Section\n",
    "These section includes the installation of some of our needed modules. It also imports the modules we will be using."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Installing Tensorflow and opencv\n",
    "# !pip install --user tensorflow==2.10.1 opencv-python\n",
    "#!pip install keras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Input"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading our data\n",
    "We will be using ORL AT&T Dataset of Faces, taken at the Olivetti Research Laboratory in Cambridge, UK. It includes 40 people, each with 10 pictures with varying facial expressions.\n",
    "\n",
    "In this section, we initialize X_train, Y_train, X_test, Y_test. The X lists represent the pictures of the individuals, the Y labels are their identifiers.\n",
    "We import the folder containing the dataset of images. The folder contains 40 folders, each containing pictures of one person. We split the folders into 35 to 5 folders for training and testing data. We convert these images into numpy arrays containing numerical values after preprocessing them. We add the numpy arrays of images to our X,Y lists accordingly."
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 1,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3160792744.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[1], line 2\u001B[1;36m\u001B[0m\n\u001B[1;33m    We will be using...\u001B[0m\n\u001B[1;37m       ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 92, 1)\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty X,Y training and test arrays\n",
    "X_train, Y_train = [], []\n",
    "X_test, Y_test = [], []\n",
    "# Define the dataset path\n",
    "dataset_path = \"dataset\"\n",
    "# List of DirEntry Objects. These objects contain path attributes.\n",
    "dataset = os.listdir(dataset_path)\n",
    "dataset = sorted(dataset)\n",
    "# Our training data is 1-35, test data is 35-40\n",
    "# Loop through the folders inside the dataset\n",
    "for folder_index in range(1,41):\n",
    "    person_name = dataset[folder_index]\n",
    "    person_folder_path = dataset_path + \"/\" + person_name\n",
    "    person_folder = os.listdir(person_folder_path)\n",
    "    # Loop through images in each person's folder\n",
    "    for img_name in person_folder:\n",
    "        img_path = person_folder_path + '/' + img_name\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        img = np.array(img)\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        # Splitting dataset_path\n",
    "        if folder_index <= 35:\n",
    "            X, Y = X_train, Y_train\n",
    "        else:\n",
    "            X, Y = X_test, Y_test\n",
    "\n",
    "        # Normalize the pixel values to [0, 1]\n",
    "        img = img / 255.0\n",
    "        X.append(img)\n",
    "        Y.append(person_name)\n",
    "        # Display the preprocessed image (Used for testing)\n",
    "        #cv2.imshow('Preprocessed Image', img)\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()\n",
    "\n",
    "# Check the shape of the image\n",
    "img_shape = X_train[0].shape\n",
    "print(img_shape)\n",
    "# Get image width and height values\n",
    "img_height, img_width = img_shape[0], img_shape[1]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating X_train, Y_train, X_test, Y_test using pairs of images and their outputs (0 or 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.19607843 0.19607843 0.19607843]\n",
      "  [0.19215686 0.19215686 0.19215686]\n",
      "  [0.19607843 0.19607843 0.19607843]\n",
      "  ...\n",
      "  [0.14901961 0.14901961 0.14901961]\n",
      "  [0.17254902 0.17254902 0.17254902]\n",
      "  [0.15686275 0.15686275 0.15686275]]\n",
      "\n",
      " [[0.21568627 0.21568627 0.21568627]\n",
      "  [0.18039216 0.18039216 0.18039216]\n",
      "  [0.19607843 0.19607843 0.19607843]\n",
      "  ...\n",
      "  [0.15686275 0.15686275 0.15686275]\n",
      "  [0.16470588 0.16470588 0.16470588]\n",
      "  [0.15686275 0.15686275 0.15686275]]\n",
      "\n",
      " [[0.19607843 0.19607843 0.19607843]\n",
      "  [0.19215686 0.19215686 0.19215686]\n",
      "  [0.19215686 0.19215686 0.19215686]\n",
      "  ...\n",
      "  [0.16470588 0.16470588 0.16470588]\n",
      "  [0.16862745 0.16862745 0.16862745]\n",
      "  [0.15686275 0.15686275 0.15686275]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.71764706 0.71764706 0.71764706]\n",
      "  [0.64705882 0.64705882 0.64705882]\n",
      "  [0.56862745 0.56862745 0.56862745]\n",
      "  ...\n",
      "  [0.5372549  0.5372549  0.5372549 ]\n",
      "  [0.50196078 0.50196078 0.50196078]\n",
      "  [0.6        0.6        0.6       ]]\n",
      "\n",
      " [[0.52156863 0.52156863 0.52156863]\n",
      "  [0.58039216 0.58039216 0.58039216]\n",
      "  [0.60784314 0.60784314 0.60784314]\n",
      "  ...\n",
      "  [0.50196078 0.50196078 0.50196078]\n",
      "  [0.52941176 0.52941176 0.52941176]\n",
      "  [0.43921569 0.43921569 0.43921569]]\n",
      "\n",
      " [[0.56470588 0.56470588 0.56470588]\n",
      "  [0.58823529 0.58823529 0.58823529]\n",
      "  [0.6627451  0.6627451  0.6627451 ]\n",
      "  ...\n",
      "  [0.53333333 0.53333333 0.53333333]\n",
      "  [0.56470588 0.56470588 0.56470588]\n",
      "  [0.38431373 0.38431373 0.38431373]]]\n",
      "[[[0.22745098 0.22745098 0.22745098]\n",
      "  [0.22352941 0.22352941 0.22352941]\n",
      "  [0.23921569 0.23921569 0.23921569]\n",
      "  ...\n",
      "  [0.16078431 0.16078431 0.16078431]\n",
      "  [0.12941176 0.12941176 0.12941176]\n",
      "  [0.18823529 0.18823529 0.18823529]]\n",
      "\n",
      " [[0.22352941 0.22352941 0.22352941]\n",
      "  [0.23137255 0.23137255 0.23137255]\n",
      "  [0.24313725 0.24313725 0.24313725]\n",
      "  ...\n",
      "  [0.14117647 0.14117647 0.14117647]\n",
      "  [0.14901961 0.14901961 0.14901961]\n",
      "  [0.15294118 0.15294118 0.15294118]]\n",
      "\n",
      " [[0.23529412 0.23529412 0.23529412]\n",
      "  [0.22745098 0.22745098 0.22745098]\n",
      "  [0.23529412 0.23529412 0.23529412]\n",
      "  ...\n",
      "  [0.14509804 0.14509804 0.14509804]\n",
      "  [0.16078431 0.16078431 0.16078431]\n",
      "  [0.12941176 0.12941176 0.12941176]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.55686275 0.55686275 0.55686275]\n",
      "  [0.3254902  0.3254902  0.3254902 ]\n",
      "  [0.85882353 0.85882353 0.85882353]\n",
      "  ...\n",
      "  [0.14901961 0.14901961 0.14901961]\n",
      "  [0.18039216 0.18039216 0.18039216]\n",
      "  [0.18431373 0.18431373 0.18431373]]\n",
      "\n",
      " [[0.58039216 0.58039216 0.58039216]\n",
      "  [0.29803922 0.29803922 0.29803922]\n",
      "  [0.89411765 0.89411765 0.89411765]\n",
      "  ...\n",
      "  [0.16862745 0.16862745 0.16862745]\n",
      "  [0.16862745 0.16862745 0.16862745]\n",
      "  [0.17254902 0.17254902 0.17254902]]\n",
      "\n",
      " [[0.54117647 0.54117647 0.54117647]\n",
      "  [0.38823529 0.38823529 0.38823529]\n",
      "  [0.88627451 0.88627451 0.88627451]\n",
      "  ...\n",
      "  [0.16862745 0.16862745 0.16862745]\n",
      "  [0.19215686 0.19215686 0.19215686]\n",
      "  [0.14117647 0.14117647 0.14117647]]]\n"
     ]
    }
   ],
   "source": [
    "from helper_functions import create_X_pairs\n",
    "def show_images(list_of_pairs):\n",
    "    count = 0\n",
    "    for pair in list_of_pairs:\n",
    "        count += 1\n",
    "        image1, image2 = pair[0], pair[1]\n",
    "        combined_image = np.zeros((img_height,img_width*2, 3))\n",
    "        combined_image[:, :img_width] = image1\n",
    "        combined_image[:, img_width:] = image2\n",
    "        print(combined_image)\n",
    "        cv2.imshow('Combined Image', combined_image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        if(count == 2):\n",
    "            break\n",
    "\n",
    "# Creating our training and data sets for pairs of images\n",
    "X_pairs_train, Y_pairs_train = create_X_pairs(X_train, 35, 150)\n",
    "X_pairs_test, Y_pairs_test = create_X_pairs(X_test, 5, 30)\n",
    "# Turning our training and testing sets into numpy arrays\n",
    "X_pairs_train = np.array(X_pairs_train)\n",
    "Y_pairs_train = np.array(Y_pairs_train)\n",
    "X_pairs_test = np.array(X_pairs_test)\n",
    "Y_pairs_test = np.array(Y_pairs_test)\n",
    "show_images(X_pairs_train)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating our Model\n",
    "### Creating the feature generating model\n",
    "The layers of this section follow the layers explained in [2]. However, more modifications will be made to this code as Max Pooling layers are incomplete. This is causing the loss value to be NaN during the training of my model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# I am referencing the code used to build the model used in [1]\n",
    "feature_generation_network = Sequential()\n",
    "feature_generation_network.add(Conv2D(filters=128,\n",
    " kernel_size=(3,3), activation='relu',\n",
    "                 input_shape=img_shape))\n",
    "feature_generation_network.add(MaxPooling2D())\n",
    "feature_generation_network.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "feature_generation_network.add(Flatten())\n",
    "feature_generation_network.add(Dense(units=128, activation='sigmoid'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 110, 90, 128)      1280      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 55, 45, 128)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 53, 43, 64)        73792     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 145856)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               18669696  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,744,768\n",
      "Trainable params: 18,744,768\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the summary of the structure of the model\n",
    "feature_generation_network.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Defining the inputs and outputs\n",
    "The outputs here refer to the network used to generate features inside our siamese neural network for each input. The two outputs of the feature_generation_network from input1 and input2 will then be compared by calculating the Euclidean distance between them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "input1, input2 = Input(shape=img_shape), Input(shape=img_shape)\n",
    "# Share the single output layer for both inputs\n",
    "output1, output2 = feature_generation_network(input1), feature_generation_network(input2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining the output of the siamese_network: Distance between our two inital outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# References [1]\n",
    "from helper_functions import euclidean_distance\n",
    "from keras.layers import Lambda\n",
    "# Creating the final layer of the SNN\n",
    "distance = Lambda(euclidean_distance, output_shape=(1,))([output1, output2])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize Siamese Neural Network Model with inputs and outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "siamese_network = Model((input1, input2), distance)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get Summary of our model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 112, 92, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 112, 92, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 128)          18744768    ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " subtract (Subtract)            (None, 128)          0           ['sequential[0][0]',             \n",
      "                                                                  'sequential[1][0]']             \n",
      "                                                                                                  \n",
      " tf.math.pow (TFOpLambda)       (None, 128)          0           ['subtract[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  (None, 1)           0           ['tf.math.pow[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.sqrt (TFOpLambda)      (None, 1)            0           ['tf.math.reduce_sum[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18,744,768\n",
      "Trainable params: 18,744,768\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_network.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training our model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compile our model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "from helper_functions import contrastive_loss\n",
    "siamese_network.compile(loss=contrastive_loss, optimizer='adam')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exporting our model to be integrated into a web application"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 8s 150ms/step - loss: 0.1751\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 8s 158ms/step - loss: 0.2403\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 8s 154ms/step - loss: 0.4086\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 8s 158ms/step - loss: 0.1616\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 8s 155ms/step - loss: 0.1532\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 8s 159ms/step - loss: 0.1065\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 8s 154ms/step - loss: 0.0778\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 8s 160ms/step - loss: 0.0581\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 9s 170ms/step - loss: 0.0426\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 0.0298\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x25ecaa978e0>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating numpy arrays for the first and second element of each pair\n",
    "X1_train = np.array([pair[0] for pair in X_pairs_train])\n",
    "X2_train = np.array([pair[1] for pair in X_pairs_train])\n",
    "# Training the model\n",
    "siamese_network.fit(x=[X1_train, X2_train], y = Y_pairs_train, batch_size = 3, epochs=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing our model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 340ms/step\n",
      "[[0.97025144]\n",
      " [0.89391136]\n",
      " [0.4291342 ]\n",
      " [1.5194192 ]\n",
      " [0.32079366]\n",
      " [0.5642118 ]\n",
      " [0.13655846]\n",
      " [1.0836482 ]\n",
      " [0.6714111 ]\n",
      " [0.6571402 ]\n",
      " [0.58907366]\n",
      " [0.77412087]\n",
      " [0.43421918]\n",
      " [0.8392836 ]\n",
      " [0.42481506]\n",
      " [0.3643305 ]\n",
      " [0.24260598]\n",
      " [0.6177844 ]\n",
      " [0.15254879]\n",
      " [0.8523122 ]\n",
      " [0.35152063]\n",
      " [0.8523122 ]\n",
      " [0.532136  ]\n",
      " [0.85002744]\n",
      " [0.21059269]\n",
      " [0.8926866 ]\n",
      " [0.31522262]\n",
      " [1.0228065 ]\n",
      " [0.24538383]\n",
      " [0.88241714]]\n"
     ]
    }
   ],
   "source": [
    "X1_test = np.array([pair[0] for pair in X_pairs_test])\n",
    "X2_test = np.array([pair[1] for pair in X_pairs_test])\n",
    "Y_predict = siamese_network.predict([X1_test,X2_test])\n",
    "print(Y_predict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Evaluating accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "for i in range(len(Y_predict)):\n",
    "    if Y_predict[i] < 0.5:\n",
    "        Y_predict[i] = 0\n",
    "    else:\n",
    "        Y_predict[i] = 1\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_pairs_test, Y_predict)\n",
    "print(\"Accuracy:\", accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving our model\n",
    "This part was causing me errors. The model was not getting saved correctly and I could not load it in another file. This is why I continued my work in this file instead of using a more structured file structure."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#siamese_network.save(\"siamese_network.h5\");"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# Creating an interface to test our model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bella's folder already exists\n",
      "Britz's folder already exists\n",
      "Giselle's folder already exists\n",
      "Idris's folder already exists\n",
      "Jackson's folder already exists\n",
      "Attendance Recorder Program\n",
      "    --------------------Options-------------------\n",
      "    'a': Show list of students\n",
      "    'b': Show list of present students\n",
      "    'c': Register student\n",
      "    'd': Delete student\n",
      "    'e': Take attendance (Not functional)\n",
      "    'f': Check model accuracy\n",
      "    'g': Reset\n",
      "    'p': Quit\n",
      "    ' ': continue\n",
      "    ----------------------------------------------\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from StudentsList import StudentsList\n",
    "from Camera import Camera\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "students_list = StudentsList(os.getcwd() + \"/students\")\n",
    "students_list.load()\n",
    "camera = Camera(students_list, siamese_network)\n",
    "op = False\n",
    "while True:\n",
    "    if not op:\n",
    "        print('''Attendance Recorder Program\n",
    "    --------------------Options-------------------\n",
    "    'a': Show list of students\n",
    "    'b': Show list of present students\n",
    "    'c': Register student\n",
    "    'd': Delete student\n",
    "    'e': Take attendance (Not functional)\n",
    "    'f': Check model accuracy\n",
    "    'g': Reset\n",
    "    'p': Quit\n",
    "    ' ': continue\n",
    "    ----------------------------------------------\n",
    "    ''')\n",
    "    op = True\n",
    "    option = input('Input your option:')\n",
    "    if option == 'a':\n",
    "        for student in students_list.get_list_of_students():\n",
    "            print(student.get_name())\n",
    "    elif option == 'b':\n",
    "        for student in students_list.get_present_students():\n",
    "            print(student.get_name())\n",
    "    elif option == 'c':\n",
    "        name = input(\"What is the name of the student: \")\n",
    "        students_list.add_student(name)\n",
    "        camera.add_student_pictures(name)\n",
    "        print(f\"Student {name} successfully registered\")\n",
    "        print()\n",
    "    elif option == 'd':\n",
    "        name = input(\"What is the name of the student: \")\n",
    "        students_list.delete_student(name)\n",
    "        print(f\"Student {name} successfully deleted\")\n",
    "        print()\n",
    "    elif option == 'e':\n",
    "        print(\"Unfortunately, this option is currently not functional\")\n",
    "        #camera.take_attendance()\n",
    "        #print(f\"Present students: {students_list.get_present_students()}\")\n",
    "    elif option == 'f':\n",
    "        for student in students_list:\n",
    "            student.set_attendance(False)\n",
    "    elif option == 'p':\n",
    "        break\n",
    "    elif option == ' ':\n",
    "        op = False\n",
    "    else:\n",
    "        print(\"Option is not valid\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
